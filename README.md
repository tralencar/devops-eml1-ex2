# IntroduÃ§Ã£o Ã  DocumentaÃ§Ã£o do Projeto DevOps-EML1-EX2

## VersÃ£o
`version = "0.1.0"`

## ğŸ”¹ Sobre o Projeto
âš™ï¸ **DevOps-EML1-EX2** Ã© um projeto de **Engenharia de Machine Learning (MLOps)** voltado Ã  **inferÃªncia de potabilidade da Ã¡gua**. Ele integra prÃ©-processamento de dados, carregamento e persistÃªncia via **Google Firestore** e automaÃ§Ã£o com Docker e Makefile.

- **Nome do Projeto**: `devops-eml1-ex2`
- **Autor**: `tralencar`
- **VersÃ£o**: `0.1.0`
- **LicenÃ§a**: `MIT`
- **Palavras-chave**: `MLOps`, `Firestore`, `qualidade da Ã¡gua`, `automaÃ§Ã£o`, `prediÃ§Ã£o`
- **Fonte dos Dados**: [Dataset (Qualidade da Ãgua)](https://www.kaggle.com/datasets/adityakadiwal/water-potability/data) do Kaggle.

---

## ğŸ”¹ VisÃ£o geral do Projeto

> O projeto **DevOps-EML1-EX2** combina prÃ¡ticas modernas de DevOps e MLOps para garantir a **execuÃ§Ã£o automatizada, segura e rastreÃ¡vel de pipelines de inferÃªncia** em Machine Learning, com foco em **infraestrutura leve**, **portabilidade com Docker** e **integraÃ§Ã£o com serviÃ§os de nuvem como o Firestore**.
> A proposta enfatiza **eficiÃªncia operacional, reprodutibilidade e confiabilidade em modelos de IA aplicados a dados ambientais crÃ­ticos**.

Neste projeto de classificaÃ§Ã£o da potabilidade da Ã¡gua, foi adotada a metodologia CRISP-DM (Cross Industry Standard Process for Data Mining) devido Ã  sua estrutura bem definida, iterativa e amplamente reconhecida na indÃºstria de ciÃªncia de dados.

O CRISP-DM orientou todas as etapas do projeto conforme as seguintes informaÃ§Ãµes:

1. Entendimento do NegÃ³cio: Definiu-se o objetivo de prever a potabilidade da Ã¡gua com base em parÃ¢metros fÃ­sico-quÃ­micos.
2. Entendimento dos Dados: Realizou-se uma anÃ¡lise exploratÃ³ria para compreender a estrutura, qualidade e desbalanceamento dos dados.
3. PreparaÃ§Ã£o dos Dados: Incluiu tratamento de valores ausentes, aplicaÃ§Ã£o de SMOTE e divisÃ£o em treino e teste.
4. Modelagem: Modelos como Random Forest e XGBoost foram otimizados com Optuna.
5. AvaliaÃ§Ã£o: O desempenho dos modelos foi comparado com base em mÃ©tricas como accuracy, recall e f1-score.
6. ImplantaÃ§Ã£o: A pipeline de inferÃªncia foi implementada com o modelo Random Forest (melhor modelo encontrado no treinamento) otimizado, executado dentro de um contÃªiner Docker. Os dados de entrada foram obtidos do Firestore, o modelo carregado via arquivo .pkl, e os resultados das prediÃ§Ãµes foram gravados de volta no Firestore com o mesmo identificador de origem.

A escolha pelo CRISP-DM garantiu organizaÃ§Ã£o, reprodutibilidade e alinhamento entre objetivos tÃ©cnicos e de negÃ³cio, tornando-o ideal para projetos de ciÃªncia de dados estruturados como este.

## Estrutura do Projeto

<pre>ğŸ“‚ DEVOPS-EML1-EX2                                   âœ… (DiretÃ³rio raiz do projeto)</pre>
<pre>â”œâ”€â”€ ğŸ“‚ .env                                          âœ… (Credenciais de serviÃ§o) - Deve ser configurado</pre>
<pre>â”‚    â””â”€â”€ serviceAccountKey.json                      ğŸ“Œ (Chave de autenticaÃ§Ã£o do Firebase/Firestore) - Deve ser configurado</pre>
<pre>â”œâ”€â”€ ğŸ“‚ data                                          âœ… (Conjuntos de dados de entrada e processados)</pre>
<pre>â”‚    â”œâ”€â”€ ğŸ“‚ cloud_input                              ğŸ“Œ (Dados para inferÃªncia sem a coluna alvo)</pre>
<pre>â”‚    â”‚    â””â”€â”€ water_potability_without_target.csv</pre>
<pre>â”‚    â”œâ”€â”€ ğŸ“‚ original_data                            ğŸ“Œ (Dados brutos com a coluna alvo)</pre>
<pre>â”‚         â””â”€â”€ water_potability.csv</pre>
<pre>â”œâ”€â”€ ğŸ“‚ notebooks                                     âœ… (Notebooks exploratÃ³rios e do CRISP-DM)</pre>
<pre>â”‚    â”œâ”€â”€ best_rf_full.pkl                            ğŸ“Œ (Modelo treinado de Random Forest)</pre>
<pre>â”‚    â”œâ”€â”€ best_xgb_full.pkl                           ğŸ“Œ (Modelo treinado de XGBoost)</pre>
<pre>â”‚    â”œâ”€â”€ crisp_dm_stages.ipynb                       ğŸ“Œ (Notebook com etapas do CRISP-DM)</pre>
<pre>â”‚    â””â”€â”€ database_init.ipynb                         ğŸ“Œ (Notebook para carregamento dos dados inicias no Firebase/Firestore)</pre>
<pre>â”œâ”€â”€ ğŸ“‚ src                                           âœ… (Scripts principais da aplicaÃ§Ã£o)</pre>
<pre>â”‚    â”œâ”€â”€ best_rf_full.pkl                            ğŸ“Œ (Modelo Random Forest pronto para produÃ§Ã£o)</pre>
<pre>â”‚    â”œâ”€â”€ firestore_init.py                           ğŸ“Œ (Script para carregamento dos dados inicias no Firebase/Firestore)</pre>
<pre>â”‚    â””â”€â”€ water_scan_main.py                          ğŸ“Œ (Script principal de prediÃ§Ã£o: carrega modelo e grava resultados no Firestore)</pre>
<pre>â”œâ”€â”€ ğŸ“„ .dockerignore                                 âœ… (Arquivos ignorados ao construir imagens Docker)</pre>
<pre>â”œâ”€â”€ ğŸ“„ .gitignore                                    âœ… (Arquivos ignorados pelo Git)</pre>
<pre>â”œâ”€â”€ ğŸ“„ .python-version                               âœ… (Define a versÃ£o do Python para ambientes virtuais)</pre>
<pre>â”œâ”€â”€ ğŸ“„ Dockerfile                                    âœ… (EspecificaÃ§Ã£o da imagem Docker do projeto)</pre>
<pre>â”œâ”€â”€ ğŸ“„ Makefile                                      âœ… (Comandos de automaÃ§Ã£o do projeto)</pre>
<pre>â”œâ”€â”€ ğŸ“„ pyproject.toml                                âœ… (ConfiguraÃ§Ã£o de dependÃªncias e ferramentas com o Poetry)</pre>
<pre>â”œâ”€â”€ ğŸ“„ README.md                                     âœ… (DocumentaÃ§Ã£o principal com instruÃ§Ãµes de uso)</pre>
<pre>â””â”€â”€ ğŸ“„ requirements-min-docker.txt                   âœ… (Conjunto mÃ­nimo de dependÃªncias para execuÃ§Ã£o via Docker)</pre>

---

## ğŸ”¹ Funcionalidades

âœ… Linguagem: `Python`  
âœ… Arquitetura leve para inferÃªncia de ML  
âœ… ConexÃ£o com Firestore via `firebase-admin`  
âœ… Carregamento e prÃ©-processamento automÃ¡tico de dados  
âœ… PrediÃ§Ã£o com `scikit-learn` (Random Forest e XGBoost compatÃ­veis)  
âœ… Registro de resultados diretamente no Firestore  
âœ… Dockerfile otimizado para produÃ§Ã£o  
âœ… AutomaÃ§Ã£o com `Makefile`  
âœ… Gerenciamento de dependÃªncias com `Poetry`  

---

## ğŸ§ª Ferramentas de Desenvolvimento

- `Poetry`, `Docker`, `Make`, `Firebase Admin SDK`, `pandas`, `scikit-learn`, `imbalanced-learn`, `optuna`

---

## ğŸ”¹ PrÃ©-requisitos

- Python >=3.11,<3.12
- Git
- Poetry
- Docker
- Make

---

## ğŸ”¹ InstalaÃ§Ã£o das DependÃªncias

### 1ï¸âƒ£ Clone o repositÃ³rio

```bash
git clone https://github.com/tralencar/devops-eml1-ex2.git
```

```bash
cd devops-eml1-ex2
```

### 2ï¸âƒ£ Instale o Poetry (se necessÃ¡rio)

```bash
pip install poetry
```

### 3ï¸âƒ£ Configure o ambiente virtual local

```bash
poetry config virtualenvs.in-project true
```

```bash
poetry shell
```

### 4ï¸âƒ£ Instale as dependÃªncias

```bash
poetry install
```

---

## ğŸ”¹ ConfiguraÃ§Ã£o Inicial do Google Cloud Firestore

Para que o pipeline possa **carregar e salvar prediÃ§Ãµes no Firestore**, Ã© necessÃ¡rio realizar uma configuraÃ§Ã£o inicial no **Firebase** do Google. Siga os passos a seguir:

### 1ï¸âƒ£ Crie um Projeto no Google Cloud

Siga os passos no seguinte vÃ­deo ["Criando um banco de dados do Cloud Firestore"](https://www.youtube.com/watch?v=aYyDjtacyO4)

1. FaÃ§a login na sua conta do gmail.
2. Acesse o site: [https://firebase.google.com](https://firebase.google.com)
3. Clique em **Go to console** na parte superior direita.
4. Crie um novo projeto com o nome (devops-eml1-ex2).
5. Anote o `ID do Projeto (devops-eml1-ex2)` para uso posterior.

### 2ï¸âƒ£ Ative o Firestore

1. No menu lateral, acesse **Firestore Database**.
2. Clique em **Criar banco de dados**.
3. Escolha o **modo de teste** e a localizaÃ§Ã£o desejada. Clique em **avanÃ§ar**.
4. Crie a **coleÃ§Ã£o `devops-eml1-ex2`**. Clique em **ativar**.

### 3ï¸âƒ£ Gere a Chave de ServiÃ§o

1. Acesse **BotÃ£o de engrenagem ao lado do texto (VisÃ£o geral do projeto)** na parte superior esquerda da tela.
2. Clique em **ConfiguraÃ§Ã£o do projeto**.
3. Clique na aba **Contas de serviÃ§o**.
4. Clique na opÃ§Ã£o **Python**.
5. Clique no botÃ£o **Gerar nova chave privada**.
6. Renomei o arquivo `.json` com o nome `serviceAccountKey.json`.
7. Baixe o arquivo `.json` e salve em `.env/serviceAccountKey.json` no seu projeto local.

### 4ï¸âƒ£ Estrutura Esperada

Seu projeto deverÃ¡ conter:
```
devops-eml1-ex2/
â”œâ”€â”€ .env/
â”‚   â””â”€â”€ serviceAccountKey.json  â† ğŸ” Chave do Firebase
```

---

## ğŸ”¹ Executar Pipeline de PrediÃ§Ã£o

### 1ï¸âƒ£ Subir Dados iniciais de teste para Firestore

> Depois da configuraÃ§Ã£o inicial do Google Cloud Firestore Ã© necessÃ¡rio adicionar os primeiros dados no banco de dados Firestore. Para isso, execute o seguinte comando no terminal de comando:

```bash
make project-init
```

> Os dados iniciais foram adicionados no Firebase com a coluna (Potability) sem informaÃ§Ãµes ainda, pois esta coluna serÃ¡ completada com base na prediÃ§Ã£o do modelo de Machine Learning nas etapas seguintes.

---

### 2ï¸âƒ£ Com Docker:

> Abra o docker desktop e em seguida execute os seguintes comandos no terminal de comando no diretÃ³rio do projeto:

```bash
make build
```

```bash
make docker-run
```

> Os dados foram atualizados no Firebase para a coluna (Potability) com base nas prediÃ§Ãµes do modelo de Machine Learning.

---

### ğŸ”¹ Verificar InstalaÃ§Ã£o

```bash
poetry run python -c "import pandas; print('InstalaÃ§Ã£o bem-sucedida!')"
```

---

## ğŸ”¹ Tarefas Automatizadas com Makefile

O projeto oferece uma sÃ©rie de comandos via `make` para facilitar a automaÃ§Ã£o de tarefas:

### ğŸ”§ InstalaÃ§Ã£o e Lockfile

```bash
make lock         # Gera o poetry.lock com a versÃ£o 1.8.3 do Poetry
```

```bash
make project-init # Instala dependÃªncias e inicializa o Firestore com os dados CSV
```

### ğŸš€ ExecuÃ§Ã£o da InferÃªncia

```bash
make run         # Executa o pipeline principal de prediÃ§Ã£o com poetry
```

### ğŸ“¦ Docker

```bash
make build       # Cria a imagem Docker
```

```bash
make docker-run  # Executa a imagem Docker
```

```bash
make clean       # Remove a imagem Docker
```

---